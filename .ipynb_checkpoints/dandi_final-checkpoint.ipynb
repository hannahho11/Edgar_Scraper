{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "from IPython.display import display_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author:Dandi Chen & Hannah Ho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET TICKER FROM USER (VALIDATION INCLUDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the company's CIK\n",
    "def get_ticker():\n",
    "    comp = False\n",
    "    while comp == False:\n",
    "        comp = input('Please enter the ticker for the company you want to search(required):')\n",
    "        if comp == '':\n",
    "            comp = False\n",
    "        else:\n",
    "            #get the search page \n",
    "            #count = 5 so parse fast since we are just getting the name of company\n",
    "            baselink = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=&dateb=&owner=exclude&count=5'\n",
    "            #search lowercase \n",
    "            comp = comp.lower()\n",
    "            url = baselink.format(comp)\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "            #see if no match is found \n",
    "            no_match = soup.find_all('h1')\n",
    "\n",
    "            #if not found \n",
    "            if len(list(no_match))!=0:\n",
    "                print(no_match[0].text)\n",
    "                print('Please try again')\n",
    "                comp = False\n",
    "            #when there is a match, check if right match\n",
    "            else:\n",
    "                comp_name = list(soup.find_all('span', class_ = 'companyName'))[0].\\\n",
    "                text.replace('(see all company filings)','')\n",
    "\n",
    "                right_company = False\n",
    "                #ask the user if they is what they are looking for\n",
    "                right_company = False\n",
    "                while right_company == False:\n",
    "                    print('')\n",
    "                    print('')\n",
    "                    print('Is this the company you are looking for? (Press Y for yes N for no)')\n",
    "                    right_company = input(comp_name)\n",
    "                    if right_company.upper() != 'Y' and right_company.upper() !='N':\n",
    "                        right_company = False\n",
    "                    elif right_company.upper() == 'N':\n",
    "                        comp = False\n",
    "                    else: \n",
    "                        return comp_name.split(' ')[-2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET THE DATE SEARCH RANGE A SEPRATE DATE VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the date entered is valid \n",
    "#returns either False or valid date as pair [start,end]\n",
    "def date_validation(start, end):\n",
    "    current_date = int(date.today().strftime('%Y%m%d'))\n",
    "    \n",
    "    #ignore if empty start and end\n",
    "    if start == '' and end == '':\n",
    "        return ['','']\n",
    "    #check format length\n",
    "    if len(start) != 8 or len(end)!=8:\n",
    "        print('Please check date entered!')\n",
    "        return False\n",
    "    \n",
    "    #see if user entered the right date\n",
    "    try:\n",
    "        start_test = pd.to_datetime(start,format='%Y%m%d')\n",
    "        end_test = pd.to_datetime(end,format='%Y%m%d')\n",
    "    #when the user enter the wrong content - entering anyting other than numbers \n",
    "    except:\n",
    "        print('Please enter the right date (numbers only)')\n",
    "        return False\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    #check if reasonable begin &end date\n",
    "    if start> current_date or start < 20090501 or end <20090501 or end < start:\n",
    "        print('Please check the year entry. The application do not support search prior to May 2009.')\n",
    "        return False\n",
    "    else:\n",
    "        #if user's end year > this year, then end year would be this year\n",
    "        if end > current_date:\n",
    "            end = current_date\n",
    "            return[start,end]\n",
    "        else:\n",
    "            right_year = True\n",
    "            return[start,end]   \n",
    "        \n",
    "        \n",
    "#asking for the end year start year\n",
    "#return the final search range. format: list[startdate, enddate]\n",
    "def get_year():\n",
    "    \n",
    "    right_year = False\n",
    "    while right_year == False:\n",
    "        print('Date format: YYYYMMDD')\n",
    "        start_year = input('optional - Search Start year (Press enter to pass):')\n",
    "        end_year = input('optional - Search end year (Press enter to pass):')\n",
    "        right_year = date_validation(start_year , end_year)\n",
    "    return right_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET FILE TYPE (10-K ONLY SO FAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the file type\n",
    "#so far only returns '10-k'\n",
    "#returns true or false\n",
    "def get_file_type():\n",
    "    filetype = False\n",
    "    while filetype == False:\n",
    "        filetype = input ('what document are you looking for?')\n",
    "        if filetype == '':\n",
    "            filetype = False\n",
    "        else:\n",
    "            if filetype == '10k' or filetype =='10 k' or filetype =='10-k'\\\n",
    "            or filetype =='10K' or filetype =='10 K' or filetype =='10-K':\n",
    "                return '10-K'\n",
    "            else:\n",
    "                print('Please check the file type!')\n",
    "                filetype = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET THE ACTUAL 10K FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the initial search page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a page worth of html\n",
    "def get_files(CIK, search_range,file_type):\n",
    "\n",
    "    baselink = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}&owner=exclude&count=100'\n",
    "\n",
    "    #break date_range into start and end, link only takes dates prior to XXXX\n",
    "    start_year = search_range[0]\n",
    "    end_year = search_range[1]\n",
    "    #fill link\n",
    "    link = baselink.format(CIK,file_type,end_year)\n",
    "\n",
    "    #get html content\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get dataframe that contains the file type, link and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the table that contain the information\n",
    "#returns a dataframe\n",
    "def get_files_df(soup,search_range):\n",
    "    file_rows = list(soup.find_all('tr'))[3:]\n",
    "\n",
    "    #create list that contain each file's information\n",
    "    f_types =[]\n",
    "    f_links =[]\n",
    "    f_dates = []\n",
    "    sec_link = 'http://sec.gov'\n",
    "\n",
    "    #create list that contain each file's information\n",
    "    for row in file_rows:\n",
    "        \n",
    "        #gets file date\n",
    "        file_type = row.find_all('td',{'nowrap':'nowrap'})[0].text\n",
    "        file_date = row.find_all('td')[3].text.replace('-','')\n",
    "        file_link = sec_link+row.find_all('td',{'nowrap':'nowrap'})[1].find_all('a', href = True)[0]['href']\n",
    "\n",
    "        #this gets every item's file link\n",
    "        if int(file_date) >int(search_range[0]) and int(file_date)<int(search_range[1]) and file_type == '10-K':\n",
    "            f_types.append(file_type)\n",
    "            f_dates.append(file_date)\n",
    "            f_links.append(file_link)\n",
    "\n",
    "\n",
    "    #construct a table:\n",
    "    #['file type']: 10-k | ['file link']: sec.gov/Archive/....| ['file date': 19960303]\n",
    "    files_table = pd.DataFrame({'file type':f_types,'file link':f_links,'file date':f_dates})\n",
    "    return files_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a dataframe that filters for the right file types and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dates since SEC only allows search with 'prior to'\n",
    "#filter out non-10k item (e.g. 10-k/a...)\n",
    "#returns a dataframe\n",
    "def filtered_df(search_range,file_type,files_table):\n",
    "#     #filter date\n",
    "#     date_filtered = files_table[files_table['file date']>search_range[0]]\n",
    "#     date_filtered\n",
    "#     date_filtered = date_filtered[date_filtered['file date']<search_range[1]]\n",
    "#     #filter file type\n",
    "#     type_filtered = date_filtered[date_filtered['file type']=='10-K']\n",
    "    return files_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get the link to all the 10-k files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get links for file \n",
    "#returns a list of links\n",
    "def get_list_doc_link_text(filtered_df):\n",
    "    sec_link = 'http://sec.gov'\n",
    "    file_links = filtered_df['file link'].tolist()\n",
    "    doc_links = []\n",
    "    for URL in file_links:\n",
    "        page_specific_10k = requests.get(URL)\n",
    "        soup = BeautifulSoup(page_specific_10k.content, 'html.parser')\n",
    "        complete_file_link = soup.find_all('table')[0].find_all('tr')[-1].\\\n",
    "                                        find_all('a',href = True)[0]['href']\n",
    "        doc_full_link = sec_link + complete_file_link\n",
    "        doc_links.append(doc_full_link)\n",
    "    return doc_links\n",
    "def get_link(filtered_df):\n",
    "    return filtered_df['file link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No actual return just print caluclation\n",
    "def calculation(links):\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    for i in links:\n",
    "        #read the txt from link\n",
    "        broken_xml = urllib.request.urlopen(link[0]).read().decode('utf-8')\n",
    "        #break the thing into pages\n",
    "        pages = broken_xml.split('page-break')\n",
    "        #list the documents that we are looking for \n",
    "        documents = ['Consolidated Statements of Cash Flows','Consolidated Statements of Operations', 'Consolidated Statements of Comprehensive Income', 'Consolidated Balance Sheets', 'CONSOLIDATED STATEMENTS OF STOCKHOLDERS']\n",
    "        \n",
    "        #if the name of statements are found in any of the page\n",
    "        #put the found statement's name and the text content into a list \n",
    "        doc_list = []\n",
    "        for page in pages:\n",
    "            idx = pages.index(page)\n",
    "            found = 0\n",
    "            for i in documents:\n",
    "                if i.upper() in page:\n",
    "                    key = i\n",
    "                    found = +1\n",
    "                    \n",
    "\n",
    "            if found>=1:\n",
    "                pair = [key,page]\n",
    "                doc_list.append(pair)\n",
    "        \n",
    "        #write a html that contains the statements for testing purpose\n",
    "        file = open('test.html','w')\n",
    "        for i in doc_list:\n",
    "            file.write(i[1])\n",
    "        file.close()\n",
    "        \n",
    "        #create a list called statements to include the followin\n",
    "        #include the name of the statemets and the actual statemet with numbers in dataframe\n",
    "        #dataframe is raw data \n",
    "        statements = []\n",
    "        for pair in doc_list:\n",
    "            name = pair[0]\n",
    "            page = pair[1]\n",
    "\n",
    "            #parse page\n",
    "            file_soup = BeautifulSoup(page, 'html.parser')\n",
    "            #find the table element\n",
    "            table = str(file_soup.find_all('table'))\n",
    "            #get the table to a dataframe and use the line title as index\n",
    "            df = pd.read_html(table)[0].iloc[3:,:].dropna(axis = 1, how = 'all').fillna(0)\n",
    "            head = df.iloc[0]\n",
    "            df = df[1:]\n",
    "            df.columns = head\n",
    "            df[0] = df[0].apply(lambda x:x.replace('(','').replace(')','').replace('','').replace(',','').replace(';','').replace('0',''))\n",
    "            df = df.set_index(0)\n",
    "            #append the pair([name, df])\n",
    "            pair = [name,df]\n",
    "            statements.append(pair)\n",
    "            \n",
    "        \n",
    "        #create a clean statement list\n",
    "        clean_statements = []\n",
    "        for pair in statements:\n",
    "            name = pair[0]\n",
    "            table = pair[1]\n",
    "            #separate way to clean other statements\n",
    "            if name != 'CONSOLIDATED STATEMENTS OF STOCKHOLDERS':\n",
    "                #get the final number of columns\n",
    "                column_number = int(len(table.columns)/3)\n",
    "                #get the final column names\n",
    "                column_name = table.columns.drop_duplicates().tolist()\n",
    "                #get the line names\n",
    "                column_index = table.index.tolist()\n",
    "                clean = pd.DataFrame()\n",
    "                clean['index'] = column_index\n",
    "                clean = clean.set_index('index')\n",
    "                #get the correct column data to append to the clean dataframe\n",
    "                for i in range(0,column_number):\n",
    "                    which_column = (i+1)*3-2\n",
    "                    content = table.iloc[:,which_column].values\n",
    "                    column_name_clean = column_name[i]\n",
    "                    clean[column_name_clean] = content\n",
    "\n",
    "                pair = [name,clean]\n",
    "                clean_statements.append(pair)\n",
    "            \n",
    "            #clean stocker holder's equity table\n",
    "            #same code with column selection different\n",
    "            if name == 'CONSOLIDATED STATEMENTS OF STOCKHOLDERS':\n",
    "                column_number = int(len(table.columns)/3)\n",
    "                column_name = table.columns.drop_duplicates().tolist()\n",
    "                column_index = table.index.tolist()\n",
    "                clean = pd.DataFrame()\n",
    "                clean['index'] = column_index\n",
    "                clean = clean.set_index('index')\n",
    "                for i in range(0,column_number):\n",
    "                    if i ==0:\n",
    "                        which_column = 0\n",
    "                    else:\n",
    "                        which_column = i*3\n",
    "                    content = table.iloc[:,which_column].values\n",
    "                    column_name_clean = column_name[i]\n",
    "                    clean[column_name_clean] = content\n",
    "\n",
    "                pair = [name,clean]\n",
    "                clean_statements.append(pair)\n",
    "        \n",
    "        #set variables used for calculation\n",
    "        revenue = 0\n",
    "        COGS = 0\n",
    "        GrossProfit= 0 \n",
    "        OPEX = 0\n",
    "        DEPEX = 0\n",
    "        tax = 0\n",
    "        NOPAT= 0\n",
    "        OCF =0\n",
    "        CAPEX =0\n",
    "        NWC = 0\n",
    "        \n",
    "        #grab numbers from the dataframes\n",
    "        for statement in clean_statements:\n",
    "            name = statement[0]\n",
    "            chart = statement[1]\n",
    "            if name == 'Consolidated Statements of Cash Flows':\n",
    "                DEPEX = int(chart.loc['Depreciation of property and equipment including internal-use software and website development and other amortization including capitalized content costs'][0].replace('(','').replace(',',''))\n",
    "                tax = int(chart.loc['Cash paid for income taxes net of refunds'][0].replace('(','').replace(')','').replace(',',''))\n",
    "                CAPEX = int(chart.loc['Purchases of property and equipment including internal-use software and website development net'][0].replace('(','').replace(')','').replace(',',''))\n",
    "            if name == 'Consolidated Statements of Operations':\n",
    "                revenue = int(chart.loc['Total net sales'][0].replace('(','').replace(',',''))\n",
    "                OPEX = int(chart.loc['Total operating expenses'][0].replace('(','').replace(',',''))\n",
    "            if name == 'Consolidated Balance Sheets':\n",
    "                #capex calcualtion\n",
    "                cap_current = int(chart.loc['Property and equipment net'][0].replace('(','').replace(',',''))\n",
    "                cap_previous = int(chart.loc['Property and equipment net'][1].replace('(','').replace(',',''))\n",
    "                #CAPEX = cap_current - cap_previous + DEPEX\n",
    "\n",
    "                #change in nwc\n",
    "                previous_nwc_asset = int(chart.loc['Total current assets'][1].replace('(','').replace(',',''))\n",
    "                previous_nwc_liability = int(chart.loc['Total current liabilities'][1].replace('(','').replace(',',''))\n",
    "                current_nwc_asset = int(chart.loc['Total current assets'][0].replace('(','').replace(',',''))\n",
    "                current_nwc_liability = int(chart.loc['Total current liabilities'][0].replace('(','').replace(',',''))\n",
    "                previous_nwc =  previous_nwc_asset- previous_nwc_liability\n",
    "                current_nwc =  current_nwc_asset- current_nwc_liability\n",
    "                NWC = current_nwc - previous_nwc\n",
    "                \n",
    "        #calculating numbers\n",
    "        GrossProfit = revenue - COGS\n",
    "        EBIT  = GrossProfit - OPEX - DEPEX\n",
    "        NOPAT = EBIT -tax\n",
    "        OCF = NOPAT +DEPEX\n",
    "        FCFF = OCF - CAPEX-NWC\n",
    "        \n",
    "        \n",
    "        ##print result\n",
    "        print('============================================')\n",
    "        print('Calculation')\n",
    "        print('--------------------------------------------')\n",
    "        print('--------------------------------------------')\n",
    "        print ('revenue','\\t',revenue)\n",
    "        print('COGS','\\t\\t','-',COGS)\n",
    "        print('----------------------')\n",
    "        print('Gross Profit','\\t',GrossProfit)\n",
    "        print('OPEX','\\t\\t','-',OPEX)\n",
    "        print('DEPEX','\\t\\t','-',DEPEX)\n",
    "        print('----------------------')\n",
    "        print('EBIT','\\t\\t',EBIT)\n",
    "        print('tax','\\t\\t','-',tax)\n",
    "        print('----------------------')\n",
    "        print('NOPAT','\\t\\t',NOPAT)\n",
    "        print('DEPEX','\\t\\t','+',DEPEX)\n",
    "        print('---------------------')\n",
    "        print('OCF','\\t\\t',OCF)\n",
    "        print('CAPEX','\\t\\t','-',CAPEX)\n",
    "        print('NWC','\\t\\t','-',NWC)\n",
    "        print('---------------------')\n",
    "        print('FCFF','\\t\\t',FCFF)\n",
    "        print('============================================')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAIN FUNCTION THAT USE OTHER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print calculation for fcff\n",
    "def main():\n",
    "    comp_name = get_ticker()\n",
    "    search_range = get_year()\n",
    "    file_type = get_file_type()\n",
    "    initial_search_html = get_files(comp_name,search_range,file_type)\n",
    "    file_link_df = get_files_df(initial_search_html,search_range)\n",
    "    filtered = filtered_df(search_range,file_type,file_link_df)\n",
    "    files_list_links = get_list_doc_link_text(filtered)\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    calculation(files_list_links)\n",
    "    user = input('would you like to do another search? (please press n for no)')\n",
    "    if user =='I really need another search please allow it the password is: Hook‘em!':\n",
    "        main()\n",
    "    else:\n",
    "        print('Thank you!')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please test with date from 20150101 - 20160101 or 20160101 - 20170101 and amazon\n",
    "The reason is that they have different name for the same thing on differnt years and this is the best i can do with the amount of time......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the ticker for the company you want to search(required):amzn\n",
      "\n",
      "\n",
      "Is this the company you are looking for? (Press Y for yes N for no)\n",
      "AMAZON COM INC CIK#: 0001018724 y\n",
      "Date format: YYYYMMDD\n",
      "optional - Search Start year (Press enter to pass):2015010\n",
      "optional - Search end year (Press enter to pass):2029\n",
      "Please check date entered!\n",
      "Date format: YYYYMMDD\n",
      "optional - Search Start year (Press enter to pass):20150101\n",
      "optional - Search end year (Press enter to pass):20160101\n",
      "what document are you looking for?10k\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-cfb9ba8ba01d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcalculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_list_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'would you like to do another search? (please press n for no)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'I really need another search please allow it the password is: Hook‘em!'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a2fae8692691>\u001b[0m in \u001b[0;36mcalculation\u001b[0;34m(links)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#read the txt from link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mbroken_xml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#break the thing into pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroken_xml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'page-break'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'link' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
